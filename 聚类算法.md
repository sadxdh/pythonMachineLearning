# 聚类算法

## 完美聚类和不可能三角

Kleinberg 2002年提出完美聚类算法需要满足以下三点：

- 同比例缩放数据，聚类结果不变
- 同组数据距离缩小，非同组数据距离放大
- 聚类算法需要能够灵活包含所有聚类的可能性

以及"不可能三角"

<img src="pics/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/image-20231009174556476.png" alt="image-20231009174556476" style="zoom: 50%;" />

参考：Kleinberg J. An impossibility theorem for clustering[J]. Advances in neural information processing systems, 2002, 15.

## 常见的四种聚类算法

### K-means

#### 1.伪代码

```伪代码
获取数据 n 个 m 维的数据
随机生成 K 个 m 维的点
while(t)
    for(int i=0;i < n;i++)
        for(int j=0;j < k;j++)
            计算点 i 到类 j 的距离
    for(int i=0;i < k;i++)
        1. 找出所有属于自己这一类的所有数据点
        2. 把自己的坐标修改为这些数据点的中心点坐标
end
```

时间复杂度：![image-20231009192756904](pics/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/image-20231009192756904.png)，其中，t 为迭代次数，k 为簇的数目，n 为样本点数，m 为样本点维度。

空间复杂度： ![image-20231009192809176](pics/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/image-20231009192809176.png)，其中，k 为簇的数目，m 为样本点维度，n 为样本点数。

#### 2. 优缺点

##### 2.1 优点

- 容易理解，聚类效果不错，虽然是**局部最优**， 但往往局部最优就够了；
- 处理大数据集的时候，该算法可以保证较好的**伸缩性**；
- 当簇近似**高斯分布**的时候，**效果非常不错**；
- 算法复杂度低。

##### 2.2 缺点

- **K 值需要人为设定**，不同 K 值得到的结果不一样；
- **对初始的簇中心敏感，不同选取方式会得到不同结果**；
- **对异常值敏感**；
- 样本只能归为一类，**不适合多分类任务**；
- **不适合太离散的分类、样本类别不平衡的分类、非凸形状的分类**。

#### 3. 算法调优与改进

针对 K-means 算法的缺点，我们可以有很多种调优方式：如数据预处理（去除异常点），合理选择 K 值，高维映射等。以下将简单介绍：

##### 3.1 数据预处理

K-means 的本质是基于欧式距离的数据划分算法，均值和方差大的维度将对数据的聚类产生决定性影响。所以未做归一化处理和统一单位的数据是无法直接参与运算和比较的。常见的数据预处理方式有：数据归一化，数据标准化。

此外，离群点或者噪声数据会对均值产生较大的影响，导致中心偏移，因此我们还需要对数据进行异常点检测。

##### 3.2 合理选择 K 值

K 值的选取对 K-means 影响很大，这也是 K-means 最大的缺点，常见的选取 K 值的方法有：手肘法、Gap statistic 方法。

手肘法：



![img](pics/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/v2-5ca4a5fe0b06b25a2b97262abb401a16_720w.webp)



当 K < 3 时，曲线急速下降；**当 K > 3 时，曲线趋于平稳**，通过手肘法我们认为拐点 **3 为 K 的最佳值**。

详细参考：[【机器学习】K-means（非常详细） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/78798251)

### DBSCAN

DBSCAN，一种密度聚类算法，常用于非线性或非球面数据集。**epsilon**和**minPts**是两个必需的参数。epsilon是附近数据点的半径，这些数据点需要被认为是足够“相似”才能开始聚类。最后，minPts是需要在半径内的数据点的最小数目。

无法聚类则变为噪声

![img](pics/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/20180725173312977)

### Mean Shift

Mean Shift算法，又称为**均值漂移算法**，Mean Shift的概念最早是由Fukunage在1975年提出的，在后来由Yizong Cheng对其进行扩充，主要提出了两点的改进：

定义了核函数；
增加了权重系数。

**不断在感兴趣区域寻找质心。**核函数的定义使得偏移值对偏移向量的贡献随之样本与被偏移点的距离的不同而不同。权重系数使得不同样本的权重不同。Mean Shift算法在聚类，图像平滑、分割以及视频跟踪等方面有广泛的应用。

本质是KDE算法，可以用等高线看出密度

![这里写图片描述](pics/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/20160511165109659)

### AGNES

**凝聚的层次聚类：**一种自底向上的策略，首先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到某个终结条件被满足。（小类->大类）
**分裂的层次聚类：**采用自顶向下的策略，它首先将所有对象置于一个簇中，然后逐渐细分为越来越小的簇，直到达到了某个终结条件。（大类->小类）

![这里写图片描述](pics/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/20170923211237983)