# 线性回归模型

倘若一个模型的评估只与一个变量成相关性，那么我们就可以使用线性回归模型根据该变量模拟生成预测变量

类似一元变量方程，线性回归就相当于拟合出该映射关系的一般函数，在输入自变量时，近似预测出可能的应变量

## 损失函数

- 损失函数（loss function）就是用来度量模型的预测值f(x)与真实值Y的差异程度的运算函数，**值越小通常说明模型对训练数据的拟合度越高**
- 相关链接：[损失函数（Loss Function）详解](https://zhuanlan.zhihu.com/p/261059231)

## 过拟合

- [过适 - 维基百科，自由的百科全书 (wikipedia.org)](https://zh.wikipedia.org/zh-hans/過適)

## 两种解决过拟合的方法

1、减少特征变量

2、正则化处理

### 两种通过正则化防止过拟合的模型

#### 岭回归模型

- 岭回归模型：岭回归模型是一种改良的**最小二乘法**，是一种能够**避免过拟合**的线性模型

- 相关链接：[最小二乘法详解](https://zhuanlan.zhihu.com/p/38128785)

- 相关链接：[sklearn官网-岭回归](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ridge_path.html)

  实验参考：[基于线性回归算法的预测模型](./4.基于线性回归算法的预测模型.jupyter)

- 相对于**线性回归模型**，岭回归模型**alpha=1.0**的均方误差并**没有减小**，但权重系数值有所**减小**

- 相对于**岭回归模型alpha=1.0**，岭回归模型**alpha=10**的均方误差**没有减小**，但权重系数值**减小**

- 相对于**岭回归模型alpha=1.0**，岭回归模型**alpha=0.1**的均方误差**有所减小**，但权重系数值**更大**

  

- 当alpha=1.0时，特征变量系数**普遍偏大**

- **当alpha=10时，特征变量系数大多在0附近，也就是说模型的复杂度大大降低，模型更不容易出现过拟合**

- 当alpha=0.1时，特征变量系数与**线性回归模型**重合，而线性回归模型并没有进行正则化处理，对应的特征变量系数值会**非常大**

- ![img](pics/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/sphx_glr_plot_ridge_path_001.png)

##### 总结

alpha值越大，模型的复杂度就越低，模型越不容易出现过拟合

alpha值越小，模型输出的不确定性就越大

- 相关链接：[正则化为什么能防止过拟合（重点地方标红了）](https://www.cnblogs.com/alexanderkun/p/6922428.html)

#### 套索回归模型

- 套索回归模型：和岭回归类似，不同的是套索模型使用**L1正则化**。**L1正则化会导致模型有一部分特征变量的系数正好等于0**